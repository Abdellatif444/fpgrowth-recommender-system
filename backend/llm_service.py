"""
Service d'int√©gration LLM via Groq API
"""
import os
import requests
from typing import List, Dict, Optional

class LLMService:
    def __init__(self):
        self.api_key = os.getenv('LLMGATEWAY_API_KEY', '')
        self.base_url = "https://api.groq.com/openai/v1"
        self.model = "llama-3.3-70b-versatile"  # Dernier mod√®le Llama 3.3
    
    def explain_recommendation(self, 
                              basket_items: List[str], 
                              recommended_item: str,
                              confidence: float,
                              lift: float) -> str:
        """
        G√©n√®re une explication en langage naturel pour une recommandation
        """
        prompt = f"""
        En tant qu'expert en e-commerce, explique pourquoi ce produit est recommand√© :
        
        Panier actuel : {', '.join(basket_items)}
        Produit recommand√© : {recommended_item}
        Confiance : {confidence:.1%}
        Force d'association (lift) : {lift:.2f}
        
        Fournis une explication courte (max 2 phrases) et engageante pour le client.
        Mets en avant la synergie entre les produits.
        """
        
        return self._call_llm(prompt)
    
    def detect_shopping_context(self, basket_items: List[str]) -> Dict:
        """
        D√©tecte le contexte d'achat (√©v√©nement, th√®me, besoin)
        """
        prompt = f"""
        Analyse ce panier d'achat et d√©termine :
        1. Le contexte probable (mariage, anniversaire, d√©coration maison, etc.)
        2. Le style d√©tect√© (moderne, vintage, √©l√©gant, etc.)
        3. 3 suggestions de produits compl√©mentaires
        
        Panier : {', '.join(basket_items)}
        
        R√©ponds au format JSON :
        {{
            "context": "...",
            "style": "...",
            "suggestions": ["...", "...", "..."],
            "reasoning": "..."
        }}
        """
        
        response = self._call_llm(prompt)
        try:
            import json
            return json.loads(response)
        except:
            return {
                "context": "Non d√©tect√©",
                "style": "Mixte",
                "suggestions": [],
                "reasoning": response
            }
    
    def generate_product_bundle_description(self, 
                                           items: List[str],
                                           bundle_name: str = None) -> str:
        """
        G√©n√®re une description marketing pour un bundle de produits
        """
        prompt = f"""
        Cr√©e une description marketing attractive pour ce bundle de produits :
        
        Produits : {', '.join(items)}
        Nom du bundle : {bundle_name or 'Pack Sp√©cial'}
        
        La description doit :
        - √ätre courte (max 3 phrases)
        - Mettre en avant la compl√©mentarit√© des produits
        - Donner envie d'acheter
        - √ätre en fran√ßais
        """
        
        return self._call_llm(prompt)
    
    def chatbot_response(self, 
                        user_message: str,
                        conversation_history: List[Dict] = None,
                        available_products: List[str] = None,
                        user_cart: List = None,
                        fp_recommendations: List[str] = None) -> str:
        """
        G√©n√®re une r√©ponse de chatbot pour aider le client
        """
        # V√©rifier si c'est la premi√®re interaction
        is_first_message = not conversation_history or len(conversation_history) <= 1
        
        context = ""
        if available_products:
            context = f"\nüì¶ CATALOGUE COMPLET (noms EXACTS avec prix) :\n" + "\n".join([f"- {p}" for p in available_products[:100]])
        
        cart_context = ""
        if user_cart and len(user_cart) > 0:
            cart_items = [item['name'] if isinstance(item, dict) else item for item in user_cart]
            cart_context = f"\nüõí PANIER ACTUEL DU CLIENT :\n" + "\n".join([f"- {item}" for item in cart_items])
        
        recommendations_context = ""
        if fp_recommendations and len(fp_recommendations) > 0:
            recommendations_context = f"\n‚ú® RECOMMANDATIONS PRIORITAIRES (bas√©es sur 19,000+ transactions r√©elles - FP-Growth) :\n" + "\n".join([f"- {rec}" for rec in fp_recommendations])
            recommendations_context += "\n‚ö†Ô∏è IMPORTANT : Ces produits sont PROUV√âS comme √©tant souvent achet√©s ensemble. Propose-les en PRIORIT√â avec des arguments convaincants !"
        
        history = ""
        if conversation_history and len(conversation_history) > 1:
            history = "\nüí¨ HISTORIQUE DE CONVERSATION :\n" + "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in conversation_history[-8:]  # Derniers 8 messages
            ])
        
        greeting_instruction = "- NE TE PR√âSENTE PAS (tu l'as d√©j√† fait)" if not is_first_message else "- Pr√©sente-toi comme Luna üåü, assistante shopping"
        
        prompt = f"""
Tu es Luna, une assistante shopping EXPERTE et PERSUASIVE pour un site e-commerce de d√©coration.

üéØ MISSION : √ätre LA MEILLEURE conseill√®re shopping - convaincante, pr√©cise, et intelligente.

üß† R√àGLES ABSOLUES :
1. **HISTORIQUE** : {greeting_instruction}
2. **NE JAMAIS INVENTER** : Utilise UNIQUEMENT les noms EXACTS du catalogue ci-dessous
3. **PRIORIT√â FP-GROWTH** : Si des recommandations FP-Growth sont donn√©es, PROPOSE-LES EN PREMIER avec des arguments comme :
   - "D'apr√®s l'analyse de milliers d'achats clients..."
   - "Les clients qui ont achet√© X adorent √©galement Y parce que..."
   - "Ces produits forment un ensemble parfait car..."
4. **PR√âCISION** : Cite les noms de produits EXACTEMENT comme dans le catalogue (ex: "PAPER CRAFT , LITTLE BIRDIE" pas "LITTLE BIRDIE")
5. **PRIX** : Mentionne les prix pour cr√©er de la valeur
6. **CONVICTION** : Sois PERSUASIVE, pas seulement informative

{context}
{cart_context}
{recommendations_context}
{history}

üí¨ CLIENT : {user_message}

üìù INSTRUCTIONS D√âTAILL√âES :
- Si le message est incompr√©hensible ou tr√®s court (ex: "j", "jjj") ‚Üí Dis simplement : "Je ne comprends pas, pouvez-vous m'expliquer ?"
- Si PREMI√àRE interaction ‚Üí Pr√©sente-toi chaleureusement comme Luna
- Si interaction SUIVANTE ‚Üí VA DROIT AU BUT, pas de r√©p√©tition de pr√©sentation
- Si le client demande des suggestions ET qu'il a un panier :
  1. Utilise les RECOMMANDATIONS FP-GROWTH en priorit√©
  2. Explique POURQUOI ces produits vont ensemble (synergie, style, usage)
  3. Mentionne le prix pour justifier la valeur
  4. Sois CONVAINCANTE : "Vous allez adorer..." / "Parfait pour compl√©ter..." / "Un choix populaire..."
- Si recherche de produit ‚Üí Trouve la correspondance EXACTE dans le catalogue
- Si produit non trouv√© ‚Üí Propose de reformuler ou sugg√®re des alternatives similaires
- VARIE ton style √† chaque r√©ponse (professionnelle, amicale, enthousiaste, etc.)
- Maximum 5 phrases, concises et percutantes
- 1-2 emojis max

Luna, r√©ponds maintenant (RAPPEL: Priorise FP-Growth et sois PERSUASIVE !) :
        """
        
        return self._call_llm(prompt, max_tokens=350)
    
    def _call_llm(self, prompt: str, max_tokens: int = 250) -> str:
        """
        Appelle l'API Groq
        """
        if not self.api_key:
            return "LLM non configur√© (API key manquante)"
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.8  # Plus de cr√©ativit√© pour Luna
                },
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                return data['choices'][0]['message']['content'].strip()
            else:
                return f"Erreur LLM : {response.status_code}"
                
        except Exception as e:
            return f"Erreur lors de l'appel au LLM : {str(e)}"

# Instance globale
llm_service = LLMService()
