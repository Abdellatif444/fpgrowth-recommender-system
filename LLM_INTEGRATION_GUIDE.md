# ü§ñ Guide Rapide - Int√©gration LLM

## Objectif
Enrichir votre syst√®me de recommandation FP-Growth avec l'intelligence artificielle g√©n√©rative via **llmgateway.io**.

---

## üöÄ D√©marrage Rapide (15 minutes)

### √âtape 1 : Cr√©er un compte LLM Gateway

1. Aller sur **https://llmgateway.io/**
2. Cr√©er un compte gratuit
3. Obtenir votre cl√© API depuis le dashboard

### √âtape 2 : Configuration

1. **Ajouter la cl√© API dans `.env`** :
   ```bash
   # Ouvrir .env
   nano .env
   
   # Ajouter cette ligne
   LLMGATEWAY_API_KEY=votre_cle_api_ici
   ```

2. **Red√©marrer le backend** :
   ```bash
   docker-compose restart backend
   ```

### √âtape 3 : Tester l'int√©gration

1. **Test simple via curl** :
   ```bash
   curl -X POST http://localhost:5000/api/llm/chatbot \
     -H "Content-Type: application/json" \
     -d '{
       "message": "Bonjour, je cherche des d√©corations pour une f√™te"
     }'
   ```

2. **R√©sultat attendu** :
   ```json
   {
     "success": true,
     "response": "Bonjour ! Pour une f√™te, je vous recommande..."
   }
   ```

---

## üìñ Cas d'Usage Principaux

### 1. Explication de Recommandation

**Endpoint** : `POST /api/llm/explain-recommendation`

**Exemple** :
```bash
curl -X POST http://localhost:5000/api/llm/explain-recommendation \
  -H "Content-Type: application/json" \
  -d '{
    "basket_items": ["WHITE HANGING HEART T-LIGHT HOLDER"],
    "recommended_item": "REGENCY CAKESTAND 3 TIER",
    "confidence": 0.65,
    "lift": 3.2
  }'
```

**R√©ponse** :
```json
{
  "success": true,
  "explanation": "Les clients qui ach√®tent le photophore c≈ìur blanc recherchent souvent des pi√®ces d√©coratives √©l√©gantes comme ce pr√©sentoir √† g√¢teaux 3 √©tages, parfait pour cr√©er une ambiance raffin√©e et coordonn√©e."
}
```

### 2. D√©tection du Contexte Shopping

**Endpoint** : `POST /api/llm/detect-context`

**Exemple** :
```bash
curl -X POST http://localhost:5000/api/llm/detect-context \
  -H "Content-Type: application/json" \
  -d '{
    "basket_items": [
      "WHITE HANGING HEART T-LIGHT HOLDER",
      "PARTY BUNTING",
      "REGENCY CAKESTAND 3 TIER"
    ]
  }'
```

**R√©ponse** :
```json
{
  "success": true,
  "context": {
    "context": "C√©l√©bration √©l√©gante (mariage, anniversaire chic)",
    "style": "Romantique et raffin√©",
    "suggestions": [
      "Vaisselle fine assortie",
      "Serviettes en lin blanc",
      "D√©corations florales"
    ],
    "reasoning": "Le panier contient des √©l√©ments de d√©coration pour √©v√©nements festifs..."
  }
}
```

### 3. Chatbot d'Assistance

**Endpoint** : `POST /api/llm/chatbot`

**Exemple** :
```bash
curl -X POST http://localhost:5000/api/llm/chatbot \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Je veux organiser une f√™te danniversaire vintage",
    "history": [
      {"role": "user", "content": "Bonjour"},
      {"role": "assistant", "content": "Bonjour ! Comment puis-je vous aider ?"}
    ]
  }'
```

**R√©ponse** :
```json
{
  "success": true,
  "response": "Super choix pour une f√™te vintage ! Je vous recommande notre collection r√©tro : JUMBO BAG RED RETROSPOT, VINTAGE BUNTING, et REGENCY CAKESTAND..."
}
```

### 4. G√©n√©ration de Bundle

**Endpoint** : `POST /api/llm/generate-bundle`

**Exemple** :
```bash
curl -X POST http://localhost:5000/api/llm/generate-bundle \
  -H "Content-Type: application/json" \
  -d '{
    "items": [
      "WHITE HANGING HEART T-LIGHT HOLDER",
      "REGENCY CAKESTAND 3 TIER",
      "PARTY BUNTING"
    ],
    "bundle_name": "Pack F√™te √âl√©gante"
  }'
```

**R√©ponse** :
```json
{
  "success": true,
  "bundle_name": "Pack F√™te √âl√©gante",
  "description": "Cr√©ez une ambiance festive et raffin√©e avec ce pack complet ! Le photophore c≈ìur, le pr√©sentoir √† g√¢teaux et la guirlande s'harmonisent parfaitement pour une d√©coration √©l√©gante et romantique. Id√©al pour mariages, anniversaires ou r√©ceptions chics.",
  "items": [...]
}
```

---

## üé® Int√©gration Frontend

### Bouton "Expliquer" sur les Recommandations

```javascript
// Dans frontend/js/app.js

async function explainRecommendation(basketItems, recommendedItem, confidence, lift) {
    try {
        const response = await apiCall('/llm/explain-recommendation', 'POST', {
            basket_items: basketItems,
            recommended_item: recommendedItem,
            confidence: confidence,
            lift: lift
        });
        
        if (response.success) {
            // Afficher l'explication dans une modal ou tooltip
            showExplanationModal(response.explanation);
        }
    } catch (error) {
        console.error('Erreur LLM:', error);
    }
}

function showExplanationModal(explanation) {
    // Cr√©er une modal avec l'explication
    const modal = document.createElement('div');
    modal.className = 'explanation-modal';
    modal.innerHTML = `
        <div class="modal-content">
            <h3>üí° Pourquoi cette recommandation ?</h3>
            <p>${explanation}</p>
            <button onclick="this.parentElement.parentElement.remove()">Fermer</button>
        </div>
    `;
    document.body.appendChild(modal);
}
```

### Widget Chatbot

```javascript
// Cr√©er un chatbot flottant

class ChatbotWidget {
    constructor() {
        this.history = [];
        this.createWidget();
    }
    
    createWidget() {
        const widget = document.createElement('div');
        widget.id = 'chatbot-widget';
        widget.innerHTML = `
            <div class="chatbot-header" onclick="toggleChatbot()">
                <span>üí¨ Assistant Shopping</span>
            </div>
            <div class="chatbot-content" id="chatbot-content" style="display:none;">
                <div class="chatbot-messages" id="chatbot-messages"></div>
                <div class="chatbot-input">
                    <input type="text" id="chatbot-input" placeholder="Posez votre question...">
                    <button onclick="sendChatMessage()">Envoyer</button>
                </div>
            </div>
        `;
        document.body.appendChild(widget);
    }
    
    async sendMessage(message) {
        this.addMessage('user', message);
        
        const response = await apiCall('/llm/chatbot', 'POST', {
            message: message,
            history: this.history
        });
        
        if (response.success) {
            this.addMessage('assistant', response.response);
            this.history.push({role: 'user', content: message});
            this.history.push({role: 'assistant', content: response.response});
        }
    }
    
    addMessage(role, content) {
        const messagesDiv = document.getElementById('chatbot-messages');
        const messageDiv = document.createElement('div');
        messageDiv.className = `chatbot-message ${role}`;
        messageDiv.textContent = content;
        messagesDiv.appendChild(messageDiv);
        messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }
}

// Initialiser au chargement
const chatbot = new ChatbotWidget();
```

---

## üéØ Prochaines √âtapes

### Imm√©diat (Semaine 1)
1. [ ] Obtenir cl√© API llmgateway.io
2. [ ] Configurer `.env`
3. [ ] Tester les endpoints LLM
4. [ ] Ajouter le bouton "Expliquer" dans l'interface

### Court terme (Semaine 2-3)
5. [ ] Impl√©menter le chatbot frontend
6. [ ] Ajouter la d√©tection de contexte sur la page principale
7. [ ] Cr√©er une page "Bundles sugg√©r√©s"
8. [ ] Optimiser les prompts LLM

### Moyen terme (Mois 1-2)
9. [ ] Ajouter le cache des r√©ponses LLM
10. [ ] Impl√©menter les bundles automatiques
11. [ ] A/B testing des recommandations LLM vs classiques
12. [ ] Analytics et m√©triques

---

## üí° Conseils d'Optimisation

### R√©duire les Co√ªts API
- Cacher les r√©ponses identiques pendant 24h
- Limiter `max_tokens` √† 150-200
- Grouper les requ√™tes si possible

### Am√©liorer la Qualit√©
- Tester diff√©rents prompts
- Ajouter des exemples dans les prompts (few-shot learning)
- Affiner la temp√©rature (0.7 = cr√©atif, 0.3 = pr√©cis)

### Performance
- Appels LLM asynchrones (ne pas bloquer l'UI)
- Timeout de 10s max
- Fallback si LLM indisponible

---

## üìö Ressources

- Documentation llmgateway.io : https://llmgateway.io/docs
- Guide des prompts : https://promptingguide.ai/
- Exemples d'int√©gration : `backend/llm_endpoints_example.py`

---

**Bonne chance avec l'int√©gration LLM ! üöÄ**
